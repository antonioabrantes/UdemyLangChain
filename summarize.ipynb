{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2972c17-e56d-483b-95bc-9e54e1fb3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import PyPDF2\n",
    "\n",
    "load_dotenv(dotenv_path='.env')\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0f35a-1626-470a-9e38-8261c34bc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_the_pdf(\n",
    "    file_dir: str,\n",
    "    max_final_token: int,\n",
    "    token_threshold: int,\n",
    "    gpt_model: str,\n",
    "    temperature: float,\n",
    "    summarizer_llm_system_role: str,\n",
    "    final_summarizer_llm_system_role: str,\n",
    "    character_overlap: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Summarizes the content of a PDF file using OpenAI's ChatGPT engine.\n",
    "\n",
    "    Args:\n",
    "        file_dir (str): The path to the PDF file.\n",
    "        max_final_token (int): The maximum number of tokens in the final summary.\n",
    "        token_threshold (int): The threshold for token count reduction.\n",
    "        gpt_model (str): The ChatGPT engine model name.\n",
    "        temperature (float): The temperature parameter for ChatGPT response generation.\n",
    "        summarizer_llm_system_role (str): The system role for the summarizer.\n",
    "\n",
    "    Returns:\n",
    "        str: The final summarized content.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    docs.extend(PyPDFLoader(file_dir).load())\n",
    "    print(f\"Document length: {len(docs)}\")\n",
    "    max_summarizer_output_token = int(\n",
    "        max_final_token/len(docs)) - token_threshold\n",
    "    full_summary = \"\"\n",
    "    counter = 1\n",
    "    print(\"Generating the summary..\")\n",
    "    # if the document has more than one pages\n",
    "    if len(docs) > 1:\n",
    "        for i in range(len(docs)):\n",
    "            # NOTE: This part can be optimized by considering a better technique for creating the prompt. (e.g: lanchain \"chunksize\" and \"chunkoverlap\" arguments.)\n",
    "\n",
    "            if i == 0:  # For the first page\n",
    "                prompt = docs[i].page_content + \\\n",
    "                    docs[i+1].page_content[:character_overlap]\n",
    "            # For pages except the fist and the last one.\n",
    "            elif i < len(docs)-1:\n",
    "                prompt = docs[i-1].page_content[-character_overlap:] + \\\n",
    "                    docs[i].page_content + \\\n",
    "                    docs[i+1].page_content[:character_overlap]\n",
    "            else:  # For the last page\n",
    "                prompt = docs[i-1].page_content[-character_overlap:] + \\\n",
    "                    docs[i].page_content\n",
    "            summarizer_llm_system_role = summarizer_llm_system_role.format(\n",
    "                max_summarizer_output_token)\n",
    "            full_summary += Summarizer.get_llm_response(\n",
    "                gpt_model,\n",
    "                temperature,\n",
    "                summarizer_llm_system_role,\n",
    "                prompt=prompt\n",
    "            )\n",
    "    else:  # if the document has only one page\n",
    "        full_summary = docs[0].page_content\n",
    "\n",
    "        print(f\"Page {counter} was summarized. \", end=\"\")\n",
    "        counter += 1\n",
    "    print(\"\\nFull summary token length:\", count_num_tokens(\n",
    "        full_summary, model=gpt_model))\n",
    "    final_summary = Summarizer.get_llm_response(\n",
    "        gpt_model,\n",
    "        temperature,\n",
    "        final_summarizer_llm_system_role,\n",
    "        prompt=full_summary\n",
    "    )\n",
    "    return final_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77d877-7403-46da-85f3-bd05b38ff5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b359140c-4f21-44a2-87bc-135f42df55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document length: 9\n",
      "Generating the summary..\n"
     ]
    }
   ],
   "source": [
    "file_dir = 'dados/bitcoin.pdf'\n",
    "docs = []\n",
    "docs.extend(PyPDFLoader(file_dir).load())\n",
    "print(f\"Document length: {len(docs)}\")\n",
    "max_final_token = 1000\n",
    "token_threshold = 100\n",
    "max_summarizer_output_token = int(\n",
    "    max_final_token/len(docs)) - token_threshold\n",
    "full_summary = \"\"\n",
    "counter = 1\n",
    "print(\"Generating the summary..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939c200a-abb3-45f9-a6e3-7e33c111ffb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin: Um Sistema de Dinheiro Eletrônico Peer-to-Peer\n",
      "Satoshi Nakamoto\n",
      "satoshin@gmx.com\n",
      "www.bitcoin.org\n",
      "Traduzido para Português de bitcoin.org/bitcoin.pdf\n",
      "por Rodrigo Silva Pinto - http://linkedin.com/in/rodrigosilvap\n",
      "Resumo. Uma versão puramente peer-to-peer de dinheiro eletrônico permitiria que\n",
      "pagamentos  on-line  fossem enviados  diretamente  de uma parte  para  outra,  sem\n",
      "passar por uma instituição financeira. As assinaturas digitais fornecem parte da\n",
      "solução, mas os principais benefícios são perdidos se um terceiro confiável ainda é\n",
      "necessário para evitar o gasto duplo. Nós propomos uma solução para o problema de\n",
      "gasto duplo usando uma rede peer-to-peer. A rede insere data e hora nas transações\n",
      "através de um hash em uma cadeia contínua de prova-de-trabalho à base de hash,\n",
      "formando um registro que não pode ser alterado sem refazer a prova-de-trabalho. A\n",
      "cadeia mais longa não só serve como prova da seqüência de eventos testemunhados,\n",
      "mas prova de que ela veio do maior pool de CPUs. Enquanto a maioria do poder das\n",
      "CPUs é controlado por nós que não estão cooperando para atacar a rede, eles irão\n",
      "gerar a cadeia mais longa e superar os atacantes. A própria rede requer estrutura\n",
      "mínima. As mensagens são espalhadas em regime de melhor esforço, e nós podem\n",
      "sair  e  regressar  a  rede  à  vontade,  aceitando  a  cadeia  mais  longa  de  prova-de-\n",
      "trabalho, como prova do que aconteceu enquanto eles estavam fora.\n",
      "1.    Introdução \n",
      "O comércio na Internet tem dependido quase exclusivamente de instituições financeiras que\n",
      "servem como terceiros confiáveis para processar pagamentos eletrônicos. Enquanto o sistema\n",
      "funciona bem para a maioria das operações, ainda sofre com as deficiências inerentes ao modelo\n",
      "baseado em confiança. Transações completamente não-reversíveis não são possíveis, uma vez\n",
      "que as instituições financeiras não podem evitar a mediação de conflitos. O custo da mediação\n",
      "aumenta os custos de transação, o que limita o tamanho mínimo prático da transação e elimina a\n",
      "possibilidade  de  pequenas  transações  ocasionais,  e  há  um  custo  mais  amplo  na  perda  da\n",
      "capacidade  de  fazer  pagamentos  não  reversível  para  serviços  não  reversíveis.  Com  a\n",
      "possibilidade  de  reversão,  a  necessidade  de  confiança  se  espalha.  Comerciantes  devem  ser\n",
      "cautelosos com os seus clientes, incomodando-os para obter mais informações do que seria de\n",
      "outra forma necessária. Uma certa percentagem de fraude é aceita como inevitável. Estes custos e\n",
      "incertezas  de  pagamento  podem ser  evitados  ao  vivo  usando  moeda  física,  mas  não  existe\n",
      "nenhum mecanismo para fazer pagamentos ao longo de um canal de comunicação sem uma parte\n",
      "confiável.\n",
      "O que é necessário é um sistema de pagamento eletrônico baseado em prova criptográfica em\n",
      "vez de confiança, permitindo a quaisquer duas partes dispostas a transacionar diretamente uma\n",
      "com a outra sem a necessidade de um terceiro confiável. Transações que são computacionalmente\n",
      "impraticáveis  de reverter protegeriam os vendedores  de fraudes  e mecanismos  rotineiros  de\n",
      "disputa poderiam ser facilmente implementados para proteger os compradores. Neste artigo, nós\n",
      "propomos uma solução para o problema de gasto duplo usando um servidor de horas distribuído\n",
      "peer-to-peer para gerar prova computacional da ordem cronológica das operações. O sistema é\n",
      "seguro desde que nós honestos controlem coletivamente mais poder de CPU do que qualquer\n",
      "grupo cooperado de nós atacantes.\n",
      "2.    Transações\n",
      "Nós definimos uma moeda eletrônica como uma cadeia de assinaturas digitais. Cada proprietário\n",
      "transfere a moeda para o seguinte por uma assinatura digital de hash da operação anterior e a\n",
      "1chave pública do dono da próxima e adicionando-os \n"
     ]
    }
   ],
   "source": [
    "character_overlap=50\n",
    "i=0\n",
    "if i == 0:  # For the first page\n",
    "    prompt = docs[i].page_content + \\\n",
    "        docs[i+1].page_content[:character_overlap]\n",
    "# For pages except the fist and the last one.\n",
    "elif i < len(docs)-1:\n",
    "    prompt = docs[i-1].page_content[-character_overlap:] + \\\n",
    "        docs[i].page_content + \\\n",
    "        docs[i+1].page_content[:character_overlap]\n",
    "else:  # For the last page\n",
    "    prompt = docs[i-1].page_content[-character_overlap:] + \\\n",
    "        docs[i].page_content\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f724956-e2e0-45fd-9cda-b0010862ea0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summarizer_llm_system_role' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summarizer_llm_system_role \u001b[38;5;241m=\u001b[39m summarizer_llm_system_role\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m      2\u001b[0m                 max_summarizer_output_token)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'summarizer_llm_system_role' is not defined"
     ]
    }
   ],
   "source": [
    "summarizer_llm_system_role = summarizer_llm_system_role.format(\n",
    "                max_summarizer_output_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b30494-c2d2-47f7-bebb-82273e515e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
