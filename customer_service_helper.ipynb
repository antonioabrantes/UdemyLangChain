{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd9e0b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='.env')\n",
    "huggingfacehub_api_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ff97f1-1812-4fb7-8511-d2999ba2c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otimi\\anaconda3\\envs\\python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert/distilbert-base-uncased-finetuned-sst-2-english, 9492296\n",
      "\n",
      "cardiffnlp/twitter-roberta-base-sentiment-latest, 4935481\n",
      "\n",
      "facebook/fasttext-language-identification, 4406897\n",
      "\n",
      "papluca/xlm-roberta-base-language-detection, 3416151\n",
      "\n",
      "facebook/bart-large-mnli, 3088471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_models\n",
    "\n",
    "def list_most_popular(task: str):\n",
    "    for rank, model in enumerate(\n",
    "        list_models(filter=task, sort=\"downloads\", direction=-1)\n",
    "):\n",
    "        if rank == 5:\n",
    "            break\n",
    "        print(f\"{model.id}, {model.downloads}\\n\")\n",
    "\n",
    "list_most_popular(\"text-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a5b356",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-t5/t5-small, 7294648\n",
      "\n",
      "facebook/bart-large-cnn, 5152473\n",
      "\n",
      "google-t5/t5-base, 2543101\n",
      "\n",
      "sshleifer/distilbart-cnn-12-6, 816964\n",
      "\n",
      "google-t5/t5-large, 487933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_most_popular(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9fc58de",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A customer\\'s coffee machine arrived ominously broken, evoking a profound sense of disbelief and despair. \"This heartbreaking display of negligence shattered my dreams of indulging in daily coffee perfection, leaving me emotionally distraught and inconsolable,\" the customer writes. \"I hope this email finds you amidst an aura of understanding, despite the tangled mess of emotions swirling within me as I write to you,\" he adds.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_portugues = \"\"\"\n",
    "Espero que este e-mail o encontre em meio a uma aura de compreensÃ£o, apesar da confusÃ£o de emoÃ§Ãµes que giram dentro de mim enquanto escrevo para vocÃª. Estou escrevendo para desabafar sobre a recente experiÃªncia infeliz que tive com uma de suas mÃ¡quinas de cafÃ© que chegou ameaÃ§adoramente quebrada, evocando um profundo sentimento de descrenÃ§a e desespero.\n",
    "\n",
    "Para definir o cenÃ¡rio, deixe-me pintar um quadro do momento em que ansiosamente desembrulhei a caixa contendo minha tÃ£o esperada mÃ¡quina de cafÃ©. A excitaÃ§Ã£o flagrante correndo em minhas veias poderia rivalizar com o fluxo vigoroso do cafÃ© atravÃ©s de sua melhor arte de expresso. No entanto, o que descobri dentro quebrou nÃ£o apenas meu espÃ­rito, mas tambÃ©m qualquer aparÃªncia de confianÃ§a que eu tinha depositado em sua estimada marca.\n",
    "\n",
    "Imagine, se puder, o choque total e a descrenÃ§a que tomaram conta de mim quando coloquei os olhos em uma mÃ¡quina de cafÃ© desgrenhada e mutilada. Seu exterior outrora elegante estava marcado pelas cicatrizes da viagem, lembrando um soldado devastado pela guerra que lutou bravamente nos campos de algum campo de batalha de cafÃ© expresso. Essa demonstraÃ§Ã£o de negligÃªncia de partir o coraÃ§Ã£o destruiu meus sonhos de me entregar Ã  perfeiÃ§Ã£o diÃ¡ria do cafÃ©, deixando-me emocionalmente perturbado e inconsolÃ¡vel\n",
    "\"\"\"  \n",
    "\n",
    "customer_email = \"\"\"\n",
    "I hope this email finds you amidst an aura of understanding, despite the tangled mess of emotions swirling within me as I write to you. I am writing to pour my heart out about the recent unfortunate experience I had with one of your coffee machines that arrived ominously broken, evoking a profound sense of disbelief and despair.\n",
    "\n",
    "To set the scene, let me paint you a picture of the moment I anxiously unwrapped the box containing my highly anticipated coffee machine. The blatant excitement coursing through my veins could rival the vigorous flow of coffee through its finest espresso artistry. However, what I discovered within broke not only my spirit but also any semblance of confidence I had placed in your esteemed brand.\n",
    "\n",
    "Imagine, if you can, the utter shock and disbelief that took hold of me as I laid eyes on a disheveled and mangled coffee machine. Its once elegant exterior was marred by the scars of travel, resembling a war-torn soldier who had fought valiantly on the fields of some espresso battlefield. This heartbreaking display of negligence shattered my dreams of indulging in daily coffee perfection, leaving me emotionally distraught and inconsolable\n",
    "\"\"\"\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "summarizer = HuggingFaceHub(\n",
    "    repo_id=\"facebook/bart-large-cnn\",\n",
    "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
    "    huggingfacehub_api_token = huggingfacehub_api_token\n",
    ")\n",
    "def summarize(llm, text) -> str:\n",
    "    return llm(f\"Summarize this: {text}!\")\n",
    "\n",
    "summarize(summarizer, customer_email)\n",
    "#summarize(summarizer, customer_portugues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7c5f54a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb\n",
    "# # https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "sentiment_model = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09aea4dc-5158-4c8e-acfb-2a26b509bcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.9814898371696472}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a6d210d-d098-4109-868c-fbd272827f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"LABEL_0\": \"Negativo\",\n",
    "    \"LABEL_1\": \"Neutro\",\n",
    "    \"LABEL_2\": \"Positivo\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "769ac044-0fec-40f7-9466-bdb64e265c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentimento: Positivo, ConfianÃ§a: 0.98\n"
     ]
    }
   ],
   "source": [
    "result = sentiment_model(\"We are very happy to show you the ðŸ¤— Transformers library.\")\n",
    "for item in result:\n",
    "    label = item['label']\n",
    "    score = item['score']\n",
    "    print(f\"Sentimento: {label_mapping[label]}, ConfianÃ§a: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e750e351-0b99-47a7-8a95-3487e8afef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: Positivo, with score: 0.9815\n",
      "label: Neutro, with score: 0.5063\n"
     ]
    }
   ],
   "source": [
    "results = sentiment_model([\"We are very happy to show you the ðŸ¤— Transformers library.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {label_mapping[result['label']]}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79cd9036",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.8218598961830139}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_model(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56cf1b29-dceb-4657-a974-ba67ccc29a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9788626432418823}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_model(\"I am so angry and sad, I want to kill myself!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52e2cba8-5edb-498e-8931-bd673cada08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_2', 'score': 0.9926880598068237}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_model(\"I am elated, I am so happy, this is the best thing that ever happened to me!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12558326-df71-4abb-81db-08089f452608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.5958543419837952}]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_model(\"I don't care. I guess it's ok, or not, I couldn't care one way or the other\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f46a2c7-fbb6-4ba6-bc6f-f364ecaefc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/main/en/main_classes/pipelines\n",
    "pipe = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71340db1-10b4-4448-9fbd-340caacdd1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.9902701377868652}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"This restaurant is awesome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "296b4170-8fbe-4b49-acbe-b75eed940b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\otimi\\anaconda3\\envs\\python\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\otimi\\.cache\\huggingface\\hub\\models--FacebookAI--roberta-large-mnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at FacebookAI/roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(model=\"FacebookAI/roberta-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28bbdb4c-7260-4dcd-88a5-fc3eb2b78239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEUTRAL', 'score': 0.7313140630722046}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"This restaurant is awesome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec421d7a-71bb-4490-8a4b-eaeef2f6f5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Liana Barrientos, 39, is charged with two counts of \"offering a false instrument for filing in the first degree\" In total, she has been married 10 times, with nine of her marriages occurring between 1999 and 2002. She is believed to still be married to four men.'}]\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/models?pipeline_tag=summarization&sort=trending\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a9278cd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "`VertexAI` is not fully defined; you should define `_LanguageModel`, then call `VertexAI.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/class-not-fully-defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 18\u001b[0m\n\u001b[0;32m      4\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mGiven this text, decide what is the issue the customer is concerned about. Valid categories are these:\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m* product issues\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m* delivery problems\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124mCategory:\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     17\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(template\u001b[38;5;241m=\u001b[39mtemplate, input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memail\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 18\u001b[0m llm \u001b[38;5;241m=\u001b[39m VertexAI(\n\u001b[0;32m     19\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-bison\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Nome do modelo no Vertex AI\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[0;32m     21\u001b[0m     max_output_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m VertexAI\u001b[38;5;241m.\u001b[39mmodel_rebuild()\n\u001b[0;32m     24\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(prompt\u001b[38;5;241m=\u001b[39mprompt, llm\u001b[38;5;241m=\u001b[39mllm, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:215\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     emit_warning()\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python\\Lib\\site-packages\\langchain_core\\load\\serializable.py:112\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python\\Lib\\site-packages\\pydantic\\_internal\\_mock_val_ser.py:99\u001b[0m, in \u001b[0;36mMockValSer.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# raise an AttributeError if `item` doesn't exist\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_val_or_ser, item)\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_message, code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code)\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: `VertexAI` is not fully defined; you should define `_LanguageModel`, then call `VertexAI.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.9/u/class-not-fully-defined"
     ]
    }
   ],
   "source": [
    "from langchain.llms import VertexAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Given this text, decide what is the issue the customer is concerned about. Valid categories are these:\n",
    "* product issues\n",
    "* delivery problems\n",
    "* missing or late orders\n",
    "* wrong product\n",
    "* cancellation request\n",
    "* refund or exchange\n",
    "* bad support experience\n",
    "* no clear reason to be upset\n",
    "\n",
    "Text: {email}\n",
    "Category:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"email\"])\n",
    "llm = VertexAI(\n",
    "    model=\"text-bison\",  # Nome do modelo no Vertex AI\n",
    "    temperature=0.7,\n",
    "    max_output_tokens=256\n",
    ")\n",
    "VertexAI.model_rebuild()\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "print(llm_chain.run(customer_email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628d57f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
